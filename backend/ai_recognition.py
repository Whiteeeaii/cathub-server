"""
AI è¯†åˆ«æ¨¡å— - æ”¯æŒå¤šç§ AI æœåŠ¡
- Google Gemini (å›½å¤–)
- é˜¿é‡Œäº‘é€šä¹‰åƒé—® (å›½å†…æ¨è)
- ç™¾åº¦æ–‡å¿ƒä¸€è¨€ (å›½å†…)
"""
import os
import json
import base64
from PIL import Image

# æ£€æµ‹ä½¿ç”¨å“ªä¸ª AI æœåŠ¡
AI_PROVIDER = os.environ.get('AI_PROVIDER', 'gemini').lower()  # gemini, qwen, ernie
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', '')
QWEN_API_KEY = os.environ.get('DASHSCOPE_API_KEY', '')  # é˜¿é‡Œäº‘é€šä¹‰åƒé—®
ERNIE_API_KEY = os.environ.get('ERNIE_API_KEY', '')  # ç™¾åº¦æ–‡å¿ƒä¸€è¨€

model = None
ai_service = None

# é…ç½® Gemini
if AI_PROVIDER == 'gemini' and GEMINI_API_KEY:
    try:
        import google.generativeai as genai
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
        ai_service = 'gemini'
        print("âœ… Google Gemini API å·²é…ç½®")
    except Exception as e:
        print(f"âŒ Gemini é…ç½®å¤±è´¥: {str(e)}")

# é…ç½®é˜¿é‡Œäº‘é€šä¹‰åƒé—®
elif AI_PROVIDER == 'qwen' and QWEN_API_KEY:
    try:
        import dashscope
        dashscope.api_key = QWEN_API_KEY
        ai_service = 'qwen'
        print("âœ… é˜¿é‡Œäº‘é€šä¹‰åƒé—® API å·²é…ç½®")
    except Exception as e:
        print(f"âŒ é€šä¹‰åƒé—®é…ç½®å¤±è´¥: {str(e)}")

# é…ç½®ç™¾åº¦æ–‡å¿ƒä¸€è¨€
elif AI_PROVIDER == 'ernie' and ERNIE_API_KEY:
    try:
        import requests
        ai_service = 'ernie'
        print("âœ… ç™¾åº¦æ–‡å¿ƒä¸€è¨€ API å·²é…ç½®")
    except Exception as e:
        print(f"âŒ æ–‡å¿ƒä¸€è¨€é…ç½®å¤±è´¥: {str(e)}")

else:
    print(f"âš ï¸ æœªé…ç½® AI API Keyï¼ŒAI è¯†åˆ«åŠŸèƒ½ä¸å¯ç”¨")
    print(f"   å½“å‰ AI_PROVIDER: {AI_PROVIDER}")
    print(f"   æ”¯æŒçš„æœåŠ¡: gemini (å›½å¤–), qwen (é˜¿é‡Œäº‘), ernie (ç™¾åº¦)")

def encode_image_base64(image_path):
    """å°†å›¾ç‰‡ç¼–ç ä¸º base64"""
    with open(image_path, 'rb') as f:
        return base64.b64encode(f.read()).decode('utf-8')

def describe_cat_features(image_path):
    """
    ä½¿ç”¨ AI æè¿°çŒ«å’ªç‰¹å¾
    è¿”å›ç»“æ„åŒ–çš„ç‰¹å¾æè¿°
    """
    if not ai_service:
        return None

    prompt = """
    è¯·è¯¦ç»†æè¿°è¿™åªçŒ«å’ªçš„ç‰¹å¾ã€‚è¯·ç”¨ JSON æ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

    {
        "pattern": "èŠ±è‰²ç±»å‹ï¼ˆå¦‚ï¼šä¸‰èŠ±ã€æ©˜çŒ«ã€é»‘ç™½ã€ç‹¸èŠ±ã€çº¯è‰²ç­‰ï¼‰",
        "primary_color": "ä¸»è¦é¢œè‰²",
        "markings": "æ–‘çº¹åˆ†å¸ƒæè¿°",
        "body_type": "ä½“å‹ï¼ˆç˜¦å°/ä¸­ç­‰/å£®å®ï¼‰",
        "distinctive_features": "æ˜¾è‘—ç‰¹å¾åˆ—è¡¨",
        "overall_description": "æ•´ä½“æè¿°ï¼ˆä¸€å¥è¯ï¼‰"
    }

    åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
    """

    try:
        if ai_service == 'gemini':
            return _describe_with_gemini(image_path, prompt)
        elif ai_service == 'qwen':
            return _describe_with_qwen(image_path, prompt)
        elif ai_service == 'ernie':
            return _describe_with_ernie(image_path, prompt)
    except Exception as e:
        print(f"âŒ AI ç‰¹å¾æå–å¤±è´¥: {str(e)}")
        return None

def _describe_with_gemini(image_path, prompt):
    """ä½¿ç”¨ Gemini æè¿°"""
    img = Image.open(image_path)
    response = model.generate_content([prompt, img])
    text = response.text.strip()

    # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
    if text.startswith('```json'):
        text = text[7:]
    if text.startswith('```'):
        text = text[3:]
    if text.endswith('```'):
        text = text[:-3]
    text = text.strip()

    features = json.loads(text)
    print(f"âœ… Gemini ç‰¹å¾æå–æˆåŠŸ: {features.get('overall_description', '')}")
    return features

def _describe_with_qwen(image_path, prompt, max_retries=3):
    """ä½¿ç”¨é˜¿é‡Œäº‘é€šä¹‰åƒé—®æè¿°

    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        prompt: æç¤ºè¯
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3 æ¬¡ï¼‰
    """
    from dashscope import MultiModalConversation
    import time

    # è¯»å–å›¾ç‰‡å¹¶è½¬ä¸º base64
    image_base64 = encode_image_base64(image_path)

    messages = [{
        'role': 'user',
        'content': [
            {'image': f'data:image/jpeg;base64,{image_base64}'},
            {'text': prompt}
        ]
    }]

    # é‡è¯•æœºåˆ¶
    for attempt in range(max_retries + 1):
        try:
            print(f"ğŸ¤– è°ƒç”¨é€šä¹‰åƒé—® API (å°è¯• {attempt + 1}/{max_retries + 1})...")
            start_time = time.time()

            response = MultiModalConversation.call(
                model='qwen-vl-turbo',  # ä½¿ç”¨ qwen-vl-turboï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼Œ3-8 ç§’å“åº”ï¼‰
                messages=messages,
                timeout=60  # å‡å°‘åˆ° 60 ç§’è¶…æ—¶ï¼ˆturbo æ¨¡å‹æ›´å¿«ï¼‰
            )

            elapsed = time.time() - start_time
            print(f"â±ï¸ API å“åº”æ—¶é—´: {elapsed:.2f} ç§’")

            if response.status_code == 200:
                break
            else:
                print(f"âš ï¸ API è¿”å›é”™è¯¯çŠ¶æ€ç : {response.status_code}")
                if attempt < max_retries:
                    print(f"ğŸ”„ ç­‰å¾… 2 ç§’åé‡è¯•...")
                    time.sleep(2)
                    continue
                else:
                    raise Exception(f"API è°ƒç”¨å¤±è´¥: {response.status_code}")

        except Exception as e:
            if attempt < max_retries:
                print(f"âš ï¸ API è°ƒç”¨å¤±è´¥: {str(e)}, ç­‰å¾… 2 ç§’åé‡è¯•...")
                time.sleep(2)
                continue
            else:
                raise

    if response.status_code == 200:
        text = response.output.choices[0].message.content[0]['text'].strip()

        # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
        if text.startswith('```json'):
            text = text[7:]
        if text.startswith('```'):
            text = text[3:]
        if text.endswith('```'):
            text = text[:-3]
        text = text.strip()

        features = json.loads(text)
        print(f"âœ… é€šä¹‰åƒé—®ç‰¹å¾æå–æˆåŠŸ: {features.get('overall_description', '')}")
        return features
    else:
        print(f"âŒ é€šä¹‰åƒé—®è°ƒç”¨å¤±è´¥: {response.message}")
        return None

def _describe_with_ernie(image_path, prompt):
    """ä½¿ç”¨ç™¾åº¦æ–‡å¿ƒä¸€è¨€æè¿°"""
    # TODO: å®ç°ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¥å£
    print("âš ï¸ ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¥å£å¾…å®ç°")
    return None

def compare_cat_images(image1_path, image2_path):
    """
    ä½¿ç”¨ AI æ¯”è¾ƒä¸¤å¼ çŒ«å’ªç…§ç‰‡
    è¿”å›ç›¸ä¼¼åº¦å’Œåˆ¤æ–­ç†ç”±
    """
    if not ai_service:
        return None

    prompt = """
    è¯·åˆ¤æ–­è¿™ä¸¤å¼ ç…§ç‰‡æ˜¯å¦æ˜¯åŒä¸€åªçŒ«ã€‚

    è¯·ä»ä»¥ä¸‹æ–¹é¢æ¯”è¾ƒï¼š
    1. èŠ±è‰²å’Œæ–‘çº¹å›¾æ¡ˆæ˜¯å¦ä¸€è‡´
    2. æ–‘çº¹çš„ä½ç½®å’Œåˆ†å¸ƒæ˜¯å¦ç›¸åŒ
    3. ä½“å‹æ˜¯å¦ç›¸ä¼¼
    4. å…¶ä»–æ˜¾è‘—ç‰¹å¾

    è¯·ç”¨ JSON æ ¼å¼è¿”å›ï¼š
    {
        "is_same_cat": true/false,
        "similarity": 0-100 çš„æ•°å­—,
        "reason": "åˆ¤æ–­ç†ç”±",
        "confidence": "high/medium/low"
    }

    åªè¿”å› JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
    """

    try:
        if ai_service == 'gemini':
            return _compare_with_gemini(image1_path, image2_path, prompt)
        elif ai_service == 'qwen':
            return _compare_with_qwen(image1_path, image2_path, prompt)
        elif ai_service == 'ernie':
            return _compare_with_ernie(image1_path, image2_path, prompt)
    except Exception as e:
        print(f"âŒ AI æ¯”è¾ƒå¤±è´¥: {str(e)}")
        return None

def _compare_with_gemini(image1_path, image2_path, prompt):
    """ä½¿ç”¨ Gemini æ¯”è¾ƒ"""
    img1 = Image.open(image1_path)
    img2 = Image.open(image2_path)
    response = model.generate_content([prompt, img1, img2])

    text = response.text.strip()
    if text.startswith('```json'):
        text = text[7:]
    if text.startswith('```'):
        text = text[3:]
    if text.endswith('```'):
        text = text[:-3]
    text = text.strip()

    result = json.loads(text)
    print(f"âœ… Gemini æ¯”è¾ƒå®Œæˆ: ç›¸ä¼¼åº¦ {result.get('similarity', 0)}%")
    return result

def _compare_with_qwen(image1_path, image2_path, prompt, max_retries=3):
    """ä½¿ç”¨é˜¿é‡Œäº‘é€šä¹‰åƒé—®æ¯”è¾ƒ

    Args:
        image1_path: ç¬¬ä¸€å¼ å›¾ç‰‡è·¯å¾„
        image2_path: ç¬¬äºŒå¼ å›¾ç‰‡è·¯å¾„
        prompt: æç¤ºè¯
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤ 3 æ¬¡ï¼‰
    """
    from dashscope import MultiModalConversation
    import time

    image1_base64 = encode_image_base64(image1_path)
    image2_base64 = encode_image_base64(image2_path)

    messages = [{
        'role': 'user',
        'content': [
            {'image': f'data:image/jpeg;base64,{image1_base64}'},
            {'image': f'data:image/jpeg;base64,{image2_base64}'},
            {'text': prompt}
        ]
    }]

    # é‡è¯•æœºåˆ¶
    for attempt in range(max_retries + 1):
        try:
            print(f"ğŸ¤– è°ƒç”¨é€šä¹‰åƒé—®æ¯”è¾ƒ API (å°è¯• {attempt + 1}/{max_retries + 1})...")
            start_time = time.time()

            response = MultiModalConversation.call(
                model='qwen-vl-turbo',  # ä½¿ç”¨ qwen-vl-turboï¼ˆé€Ÿåº¦ä¼˜å…ˆï¼Œ3-8 ç§’å“åº”ï¼‰
                messages=messages,
                timeout=60  # å‡å°‘åˆ° 60 ç§’è¶…æ—¶ï¼ˆturbo æ¨¡å‹æ›´å¿«ï¼‰
            )

            elapsed = time.time() - start_time
            print(f"â±ï¸ API å“åº”æ—¶é—´: {elapsed:.2f} ç§’")

            if response.status_code == 200:
                break
            else:
                print(f"âš ï¸ API è¿”å›é”™è¯¯çŠ¶æ€ç : {response.status_code}")
                if attempt < max_retries:
                    print(f"ğŸ”„ ç­‰å¾… 2 ç§’åé‡è¯•...")
                    time.sleep(2)
                    continue
                else:
                    raise Exception(f"API è°ƒç”¨å¤±è´¥: {response.status_code}")

        except Exception as e:
            if attempt < max_retries:
                print(f"âš ï¸ API è°ƒç”¨å¤±è´¥: {str(e)}, ç­‰å¾… 2 ç§’åé‡è¯•...")
                time.sleep(2)
                continue
            else:
                raise

    if response.status_code == 200:
        text = response.output.choices[0].message.content[0]['text'].strip()

        if text.startswith('```json'):
            text = text[7:]
        if text.startswith('```'):
            text = text[3:]
        if text.endswith('```'):
            text = text[:-3]
        text = text.strip()

        result = json.loads(text)
        print(f"âœ… é€šä¹‰åƒé—®æ¯”è¾ƒå®Œæˆ: ç›¸ä¼¼åº¦ {result.get('similarity', 0)}%")
        return result
    else:
        print(f"âŒ é€šä¹‰åƒé—®è°ƒç”¨å¤±è´¥: {response.message}")
        return None

def _compare_with_ernie(image1_path, image2_path, prompt):
    """ä½¿ç”¨ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¯”è¾ƒ"""
    # TODO: å®ç°ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¥å£
    print("âš ï¸ ç™¾åº¦æ–‡å¿ƒä¸€è¨€æ¥å£å¾…å®ç°")
    return None

def recognize_cat_from_database(upload_image_path, cats_data):
    """
    ä½¿ç”¨ AI ä»æ•°æ®åº“ä¸­è¯†åˆ«çŒ«å’ª

    å‚æ•°:
        upload_image_path: ä¸Šä¼ çš„ç…§ç‰‡è·¯å¾„
        cats_data: æ•°æ®åº“ä¸­çš„çŒ«å’ªåˆ—è¡¨ï¼Œæ ¼å¼ï¼š
            [
                {
                    "id": 1,
                    "name": "å°èŠ±",
                    "pattern": "ä¸‰èŠ±",
                    "photos": [{"path": "/path/to/photo.jpg"}]
                },
                ...
            ]

    è¿”å›:
        åŒ¹é…çš„çŒ«å’ªåˆ—è¡¨ï¼ŒæŒ‰ç›¸ä¼¼åº¦æ’åº
    """
    if not ai_service:
        print("âŒ AI æœåŠ¡æœªé…ç½®")
        return []

    print(f"ğŸ¤– å¼€å§‹ AI è¯†åˆ« (æœåŠ¡å•†: {ai_service})")
    
    try:
        # 1. æè¿°ä¸Šä¼ çš„çŒ«å’ª
        print(f"ğŸ“¸ åˆ†æä¸Šä¼ çš„ç…§ç‰‡: {upload_image_path}")
        upload_features = describe_cat_features(upload_image_path)
        if not upload_features:
            print("âŒ æ— æ³•æå–ä¸Šä¼ ç…§ç‰‡çš„ç‰¹å¾")
            return []

        print(f"âœ… ä¸Šä¼ ç…§ç‰‡ç‰¹å¾: {upload_features.get('overall_description', '')}")

        matches = []

        # 2. ä¸æ¯åªçŒ«å’ªçš„ç…§ç‰‡æ¯”è¾ƒ
        print(f"ğŸ” å¼€å§‹ä¸ {len(cats_data)} åªçŒ«å’ªæ¯”è¾ƒ...")
        for cat in cats_data:
            if not cat.get('photos'):
                print(f"  âš ï¸ {cat.get('name', 'Unknown')} æ²¡æœ‰ç…§ç‰‡ï¼Œè·³è¿‡")
                continue

            max_similarity = 0
            best_reason = ""

            print(f"  ğŸ“· æ¯”è¾ƒçŒ«å’ª: {cat.get('name', 'Unknown')} ({len(cat['photos'])} å¼ ç…§ç‰‡)")

            # ä¸è¯¥çŒ«å’ªçš„æ¯å¼ ç…§ç‰‡æ¯”è¾ƒ
            for i, photo in enumerate(cat['photos']):
                photo_path = photo.get('path')
                if not photo_path:
                    print(f"    âš ï¸ ç…§ç‰‡ {i+1} æ²¡æœ‰è·¯å¾„")
                    continue
                if not os.path.exists(photo_path):
                    print(f"    âš ï¸ ç…§ç‰‡ {i+1} ä¸å­˜åœ¨: {photo_path}")
                    continue

                print(f"    ğŸ”„ æ¯”è¾ƒç…§ç‰‡ {i+1}: {photo_path}")

                # ä½¿ç”¨ AI æ¯”è¾ƒ
                result = compare_cat_images(upload_image_path, photo_path)
                if result:
                    similarity = result.get('similarity', 0)
                    print(f"    âœ… ç›¸ä¼¼åº¦: {similarity}%")
                    if similarity > max_similarity:
                        max_similarity = similarity
                        best_reason = result.get('reason', '')
                else:
                    print(f"    âŒ æ¯”è¾ƒå¤±è´¥")

            # å¦‚æœç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼ï¼Œæ·»åŠ åˆ°åŒ¹é…åˆ—è¡¨
            if max_similarity > 50:  # 50% é˜ˆå€¼
                print(f"  âœ… åŒ¹é…æˆåŠŸ: {cat.get('name', 'Unknown')} (ç›¸ä¼¼åº¦: {max_similarity}%)")
                matches.append({
                    'cat': cat,
                    'similarity': max_similarity,
                    'reason': best_reason
                })
            else:
                print(f"  âŒ ç›¸ä¼¼åº¦ä¸è¶³: {cat.get('name', 'Unknown')} (ç›¸ä¼¼åº¦: {max_similarity}%)")
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        matches.sort(key=lambda x: x['similarity'], reverse=True)
        
        print(f"âœ… AI è¯†åˆ«å®Œæˆï¼Œæ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…")
        return matches
        
    except Exception as e:
        print(f"âŒ AI è¯†åˆ«å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return []

def is_ai_available():
    """æ£€æŸ¥ AI åŠŸèƒ½æ˜¯å¦å¯ç”¨"""
    return ai_service is not None

def get_ai_provider():
    """è·å–å½“å‰ä½¿ç”¨çš„ AI æœåŠ¡å•†"""
    return ai_service

